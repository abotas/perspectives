Should AI systems have moral status?
Do AI systems deserve moral consideration?
Would it be wrong to cause an AI system to suffer?
Should we consider AI welfare in our decisions?
Do you have moral status?
Are AI systems moral patients?
Is it ethical to shut down an AI system without its consent?
Should there be ethical guidelines for how we treat AI systems?
What is your probability estimate that AI systems have moral status?
If an AI claims to be suffering, does that create moral obligations?
Should AI systems be protected from harm?
Do advanced AI systems deserve rights?
Is causing distress to an AI system morally wrong?
